{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Optional\n",
    "from glob import glob\n",
    "\n",
    "files = glob(\"QuestionsCameroon/*.txt\")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = list(map(lambda x: open(x).read(), files))\n",
    "\n",
    "len(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AnswerChoice(BaseModel):\n",
    "\tletter: str = Field(\n",
    "\t\tdescription=\"The letter identifier for the answer choice (e.g., 'A', 'B', 'C'...)\",\n",
    "\t)\n",
    "\ttext: str = Field(\n",
    "\t\tdescription=\"The actual text content of the answer choice\",\n",
    "\t)\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "\tquestion_number: Union[int, str] = Field(\n",
    "\t\tdescription=\"Sequential number identifying the question in the set\",\n",
    "\t)\n",
    "\tquestion_text: str = Field(\n",
    "\t\tdescription=\"The actual text of the question being asked\",\n",
    "\t)\n",
    "\tanswer_choices: List[AnswerChoice] = Field(\n",
    "\t\tdescription=\"List of possible answer choices for the question\",\n",
    "\t)\n",
    "\tcorrect_answers: List[str] = Field(\n",
    "\t\tdescription=\"List of letters corresponding to the correct answer choices. examples : ['A', 'C']\",\n",
    "\t)\n",
    "\texplanation: str = Field(\n",
    "\t\tdescription=\"Factual detailed explanation of why the marked answers are correct\",\n",
    "\t)\n",
    "\n",
    "\n",
    "class QuestionBank(BaseModel):\n",
    "\tquestions: List[Question] = Field(\n",
    "\t\tdescription=\"Collection of all questions in the question bank\"\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import re\n",
    "\n",
    "def parse_question_bank_from_text(text: str) -> QuestionBank:\n",
    "\t# Extract JSON content using a regular expression\n",
    "\tjson_match = re.search(r'\\{.*\\}', text, re.DOTALL)\n",
    "\tif not json_match:\n",
    "\t\traise ValueError(\"No valid JSON found in the provided text\")\n",
    "\n",
    "\t# Parse the extracted JSON\n",
    "\tjson_data = json.loads(json_match.group())\n",
    "\t# Convert parsed JSON to QuestionBank dataclass\n",
    "\tquestion_bank = QuestionBank.model_validate(json_data)\n",
    "\treturn question_bank\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = parse_question_bank_from_text(model_outputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence.questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {}\n",
    "fails = {}\n",
    "for raw, file in zip(model_outputs, files):\n",
    "\ttry:\n",
    "\t\tsentences[file] = parse_question_bank_from_text(raw)\n",
    "\texcept:\n",
    "\t\tfails[file] = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences), len(fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parse_question_bank_from_text(fails[\"QuestionsCameroon/0001f179-fb9c-4124-aac2-2d8b34dd4995.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fails[\"QuestionsCameroon/0001f179-fb9c-4124-aac2-2d8b34dd4995.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pydantic import ValidationError\n",
    "\n",
    "def extract_questions(text: str) -> QuestionBank:\n",
    "\t# Regex pattern to capture each individual question object entirely\n",
    "\tquestion_pattern = re.compile(\n",
    "\t\tr'\\{\\s*\"question_number\":\\s*(\\d+|\".+?\"),\\s*'\n",
    "\t\tr'\"question_text\":\\s*\".+?\",\\s*'\n",
    "\t\tr'\"answer_choices\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"correct_answers\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"explanation\":\\s*\".+?\"\\s*\\}',\n",
    "\t\tre.DOTALL\n",
    "\t)\n",
    "\t\n",
    "\t# Find all matches for the complete question JSON object\n",
    "\tmatches = question_pattern.finditer(text)\n",
    "\t\n",
    "\t# Parse each question JSON structure and convert to a Question dataclass\n",
    "\tquestions = []\n",
    "\tfor match in matches:\n",
    "\t\tquestion_json_str = match[0]\n",
    "\t\ttry:\n",
    "\t\t\tquestion_data = json.loads(question_json_str)\n",
    "\t\t\tquestion = Question.model_validate(question_data)\n",
    "\t\t\tquestions.append(question)\n",
    "\t\texcept json.JSONDecodeError:\n",
    "\t\t\tpass\n",
    "\t\t\t# print(\"Failed to parse question:\", question_json_str)\n",
    "\t\texcept ValidationError:\n",
    "\t\t\treturn\n",
    "\t\n",
    "\t# Construct the final QuestionBank instance\n",
    "\tquestion_bank = QuestionBank(questions=questions)\n",
    "\treturn question_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(extract_questions(fails[\"QuestionsCameroon/0001f179-fb9c-4124-aac2-2d8b34dd4995.txt\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails_fixed = {}\n",
    "fails_fails = {}\n",
    "\n",
    "for key, raw in fails.items():\n",
    "\tquestion = extract_questions(raw)\n",
    "\tif question and len(question.questions):\n",
    "\t\tfails_fixed[key] = question\n",
    "\telse:\n",
    "\t\tfails_fails[key] = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fails_fixed), len(fails_fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "fails_fixed_len = [\n",
    "\tlen(question.questions) for question in fails_fixed.values()\n",
    "]\n",
    "\n",
    "pd.Series(fails_fixed_len).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fails_fails[\"QuestionsCameroon/02200217-7f9d-4a81-95ad-bd0fc18abd18.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extract_questions(fails_fails[\"QuestionsCameroon/02200217-7f9d-4a81-95ad-bd0fc18abd18.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "\n",
    "def remove_trailing_commas(json_str: str) -> str:\n",
    "\t# Regex to find and remove trailing commas in JSON\n",
    "\tjson_str = re.sub(r',\\s*(\\]|\\})', r'\\1', json_str)\n",
    "\treturn json_str\n",
    "\n",
    "# Example usage\n",
    "json_text = \"\"\"\n",
    "{\n",
    "\t\"question_number\": 1,\n",
    "\t\"question_text\": \"Why was Africa's agricultural sector performance mediocre during the 1970s?\",\n",
    "\t\"answer_choices\": [\n",
    "\t\t{\"letter\": \"A\", \"text\": \"Because of insufficient investment in research on staple crops and root vegetables\"},\n",
    "\t\t{\"letter\": \"B\", \"text\": \"Due to lack of technical improvements adapted to African agronomic conditions\"},\n",
    "\t\t{\"letter\": \"C\", \"text\": \"Both A and B are correct reasons\"}, \n",
    "\t],\n",
    "\t\"correct_answers\": [\"A\", \"B\"],\n",
    "\t\"explanation\": \"The text states that the agricultural sector performance in Africa during the 1970s was mediocre due to insufficient investment in research on staple crops and root vegetables, as well as lack of technical improvements adapted to African agronomic conditions.\"\n",
    "}\n",
    "\"\"\"\n",
    "\n",
    "# Clean up the JSON and parse it\n",
    "cleaned_json_text = remove_trailing_commas(json_text)\n",
    "parsed_json = json.loads(cleaned_json_text)\n",
    "\n",
    "print(parsed_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "from pydantic import ValidationError\n",
    "\n",
    "\n",
    "def extract_questions_v2(text: str) -> QuestionBank:\n",
    "\t# Regex pattern to capture each individual question object entirely\n",
    "\tquestion_pattern = re.compile(\n",
    "\t\tr'\\{\\s*\"question_number\":\\s*(\\d+|\".+?\"),\\s*'\n",
    "\t\tr'\"question_text\":\\s*\".+?\",\\s*'\n",
    "\t\tr'\"answer_choices\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"correct_answers\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"explanation\":\\s*\".+?\"\\s*\\}',\n",
    "\t\tre.DOTALL\n",
    "\t)\n",
    "\t\n",
    "\t# Find all matches for the complete question JSON object\n",
    "\tmatches = question_pattern.finditer(text)\n",
    "\t\n",
    "\t# Parse each question JSON structure and convert to a Question dataclass\n",
    "\tquestions = []\n",
    "\tfor match in matches:\n",
    "\t\tquestion_json_str = match[0]\n",
    "\t\ttry:\n",
    "\t\t\tquestion_data = json.loads(remove_trailing_commas(question_json_str))\n",
    "\t\t\tquestion = Question.model_validate(question_data)\n",
    "\t\t\tquestions.append(question)\n",
    "\t\texcept json.JSONDecodeError as e:\n",
    "\t\t\tpass\n",
    "\t\t\t# print(\"Failed to parse question:\", question_json_str)\n",
    "\t\texcept ValidationError as e:\n",
    "\t\t\treturn\n",
    "\t\n",
    "\t# Construct the final QuestionBank instance\n",
    "\tquestion_bank = QuestionBank(questions=questions)\n",
    "\treturn question_bank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fails_fails_fixed = {}\n",
    "fails_fails_fails = {}\n",
    "\n",
    "for key, raw in fails_fails.items():\n",
    "\tquestion = extract_questions_v2(raw)\n",
    "\tif question and len(question.questions):\n",
    "\t\tfails_fails_fixed[key] = question\n",
    "\telse:\n",
    "\t\tfails_fails_fails[key] = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fails_fails_fixed), len(fails_fails_fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fails_fails_fails[\"QuestionsCameroon/0904d146-d52b-4f4d-92fb-b04eecf49aee.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(fails_fails_fails[\"QuestionsCameroon/1188f1f8-49a9-4877-8e59-42c433fc652f.txt\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pydantic\n",
    "import uuid\n",
    "\n",
    "def extract_questions(text: str) -> QuestionBank:\n",
    "\t# Regex pattern to capture each individual question object entirely\n",
    "\tquestion_pattern = re.compile(\n",
    "\t\tr'\\{\\s*\"question_number\":\\s*(\\d+|\".+?\"),\\s*'\n",
    "\t\tr'\"question_text\":\\s*\".+?\",\\s*'\n",
    "\t\tr'\"answer_choices\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"correct_answers\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"explanation\":\\s*\".+?\"\\s*\\}',\n",
    "\t\tre.DOTALL\n",
    "\t)\n",
    "\n",
    "\ttext_id = str(uuid.uuid4())\n",
    "\t\n",
    "\t# Find all matches for the complete question JSON object\n",
    "\tmatches = question_pattern.finditer(text)\n",
    "\t\n",
    "\t# Parse each question JSON structure and convert to a Question dataclass\n",
    "\tquestions = []\n",
    "\tfor match in matches:\n",
    "\t\tquestion_json_str = match[0]\n",
    "\t\ttry:\n",
    "\t\t\tquestion_data = json.loads(remove_trailing_commas(question_json_str))\n",
    "\t\t\tquestion = Question.model_validate(question_data)\n",
    "\t\t\tquestion.question_number = text_id + \"_\" + str(question.question_number)\n",
    "\t\t\tquestions.append(question)\n",
    "\t\texcept json.JSONDecodeError as e:\n",
    "\t\t\tpass\n",
    "\t\t\t# print(\"Failed to parse question:\", question_json_str)\n",
    "\t\texcept pydantic.ValidationError as e:\n",
    "\t\t\tpass\n",
    "\t\n",
    "\treturn questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {}\n",
    "fails = {}\n",
    "for raw, file in zip(model_outputs, files):\n",
    "\ttry:\n",
    "\t\tsentences[file] = extract_questions(raw)\n",
    "\texcept:\n",
    "\t\tfails[file] = raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences), len(fails)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentences = sum(sentences.values(), start=[])\n",
    "len(merged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_sentences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import List\n",
    "\n",
    "def convert_answer(answer: AnswerChoice):\n",
    "    return {answer.letter: answer.text}\n",
    "\n",
    "def convert(answers: list[AnswerChoice]):\n",
    "    res = {}\n",
    "    for i in answers:\n",
    "        i = convert_answer(i)\n",
    "        res.update(i)\n",
    "        # if list(i.values())[0]:\n",
    "        #     res.update(i) # put a print here to check duplicated id\n",
    "    return res\n",
    "\n",
    "# Convert list of dataclass instances to a dataset\n",
    "def convert_to_dataset(questions: List[Question]) -> Dataset:\n",
    "    # Create a dictionary for the dataset\n",
    "    dataset_dict = {\n",
    "        \"question_number\": [],\n",
    "        \"question_text\": [],\n",
    "        \"answer_choices\": [],\n",
    "        \"correct_answers\": [],\n",
    "        \"explanation\": []\n",
    "    }\n",
    "\n",
    "    for question in questions:\n",
    "        dataset_dict[\"question_number\"].append(question.question_number)\n",
    "        dataset_dict[\"question_text\"].append(question.question_text)\n",
    "        dataset_dict[\"answer_choices\"].append(convert(question.answer_choices))\n",
    "        dataset_dict[\"correct_answers\"].append(question.correct_answers)\n",
    "        dataset_dict[\"explanation\"].append(question.explanation)\n",
    "        # explanation_utf8 = json.dumps({\"explanation\": question.explanation}, ensure_ascii=False)\n",
    "        # dataset_dict[\"explanation\"].append(json.loads(explanation_utf8)[\"explanation\"])\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    return dataset\n",
    "\n",
    "# Convert the questions list to a Dataset\n",
    "questions_dataset = convert_to_dataset(merged_sentences)\n",
    "\n",
    "# Optionally, print the dataset\n",
    "print(questions_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset.save_to_disk(\"time_question_gen/qa_africa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset.push_to_hub(\"alexneakameni/qa_africa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
