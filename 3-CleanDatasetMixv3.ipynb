{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import List, Union, Optional\n",
    "from glob import glob\n",
    "\n",
    "files = (\n",
    "    glob(\"QuestionsCameroon/LLama32/*.txt\")\n",
    "    + glob(\"QuestionsCameroon/Mistral/*/*.txt\")\n",
    "    + glob(\"QuestionsCameroon/MixLlama3.1/*.txt\")\n",
    "    + glob(\"QuestionsCameroon/Mistral12B/*/*.txt\")\n",
    ")\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_outputs = list(map(lambda x: open(x).read(), files))\n",
    "\n",
    "len(model_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "import random\n",
    "\n",
    "\n",
    "class AnswerChoice(BaseModel):\n",
    "    letter: str\n",
    "    text: str\n",
    "\n",
    "    def __eq__(self, value: \"AnswerChoice\") -> bool:\n",
    "        return self.text == value.text\n",
    "\n",
    "\n",
    "def convert_answer(answer: AnswerChoice):\n",
    "    letter = \"\".join(i for i in answer.letter.upper() if i in \"ABCDE\")\n",
    "    return letter, answer.text\n",
    "\n",
    "\n",
    "def convert(answers: list[AnswerChoice]) -> dict[str, str]:\n",
    "    res = {}\n",
    "    for i in answers:\n",
    "        a, b = convert_answer(i)\n",
    "        if b is not None and a:\n",
    "            res[a] = b\n",
    "    return res\n",
    "\n",
    "\n",
    "class Question(BaseModel):\n",
    "    question_number: Union[int, str]\n",
    "    question_text: str\n",
    "    answer_choices: List[AnswerChoice]\n",
    "    correct_answers: List[str]\n",
    "    explanation: str\n",
    "\n",
    "    def __eq__(self, value: \"Question\") -> bool:\n",
    "        return (\n",
    "            self.question_text == value.question_text\n",
    "            and self.answer_choices == value.answer_choices\n",
    "        )\n",
    "\n",
    "    def model_post_init(self, __context: Any) -> None:\n",
    "        answer_choices = convert(self.answer_choices)\n",
    "        self.answer_choices = [\n",
    "            AnswerChoice(letter=i, text=j) for i, j in answer_choices.items()\n",
    "        ]\n",
    "        for i, key in enumerate(self.correct_answers):\n",
    "            if key in answer_choices:\n",
    "                continue\n",
    "            flag = False\n",
    "            for k, w in answer_choices.items():\n",
    "                if w.strip() == key.strip():\n",
    "                    key = k\n",
    "                    flag = True\n",
    "                    continue\n",
    "            if not flag:\n",
    "                key = [i for i in key.upper() if i in \"ABCDE\" and i in answer_choices]\n",
    "                if key:\n",
    "                    self.correct_answers.extend(key)\n",
    "                key = None  # print this issue ?\n",
    "            self.correct_answers[i] = key\n",
    "        self.correct_answers = list(set([i for i in self.correct_answers if i]))\n",
    "\n",
    "        self.shuffle_choices()\n",
    "        return super().model_post_init(__context)\n",
    "\n",
    "    def shuffle_choices(self):\n",
    "        # Store the original letters and their positions\n",
    "        original_positions = {choice.letter: choice for choice in self.answer_choices}\n",
    "\n",
    "        # Shuffle the answer choices randomly\n",
    "        random.shuffle(self.answer_choices)\n",
    "\n",
    "        # Update the letters to retain the original alphabetical order\n",
    "        for i, letter in enumerate(sorted(original_positions.keys())):\n",
    "            self.answer_choices[i].letter = letter\n",
    "\n",
    "        self._update_correct_answers(original_positions)\n",
    "\n",
    "    def _update_correct_answers(self, original_positions: dict[str, AnswerChoice]):\n",
    "        # Find the new letter(s) corresponding to the original correct answers\n",
    "        updated_answers = []\n",
    "        for answer in self.correct_answers:\n",
    "            # Look up the original answer text\n",
    "            original_text = original_positions[answer].text\n",
    "            # Find the new letter for this text in the shuffled answer choices\n",
    "            for choice in self.answer_choices:\n",
    "                if choice.text == original_text:\n",
    "                    updated_answers.append(choice.letter)\n",
    "                    break\n",
    "        self.correct_answers = updated_answers\n",
    "\n",
    "\n",
    "class QuestionBank(BaseModel):\n",
    "    questions: List[Question] = Field(\n",
    "        description=\"Collection of all questions in the question bank\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import json\n",
    "import pydantic\n",
    "import uuid\n",
    "\n",
    "\n",
    "\n",
    "def remove_trailing_commas(json_str: str) -> str:\n",
    "\t# Regex to find and remove trailing commas in JSON\n",
    "\tjson_str = re.sub(r',\\s*(\\]|\\})', r'\\1', json_str)\n",
    "\treturn json_str\n",
    "\n",
    "\n",
    "def extract_questions(text: str) -> QuestionBank:\n",
    "\t# Regex pattern to capture each individual question object entirely\n",
    "\tquestion_pattern = re.compile(\n",
    "\t\tr'\\{\\s*\"question_number\":\\s*(\\d+|\".+?\"),\\s*'\n",
    "\t\tr'\"question_text\":\\s*\".+?\",\\s*'\n",
    "\t\tr'\"answer_choices\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"correct_answers\":\\s*\\[.*?\\],\\s*'\n",
    "\t\tr'\"explanation\":\\s*\".+?\"\\s*\\}',\n",
    "\t\tre.DOTALL\n",
    "\t)\n",
    "\n",
    "\ttext_id = str(uuid.uuid4())\n",
    "\t\n",
    "\t# Find all matches for the complete question JSON object\n",
    "\tmatches = question_pattern.finditer(text)\n",
    "\t\n",
    "\t# Parse each question JSON structure and convert to a Question dataclass\n",
    "\tquestions = []\n",
    "\tfor match in matches:\n",
    "\t\tquestion_json_str = match[0]\n",
    "\t\ttry:\n",
    "\t\t\tquestion_data = json.loads(remove_trailing_commas(question_json_str))\n",
    "\t\t\tquestion = Question.model_validate(question_data)\n",
    "\t\t\tquestion.question_number = text_id + \"_\" + str(question.question_number)\n",
    "\t\t\tquestions.append(question)\n",
    "\t\texcept json.JSONDecodeError as e:\n",
    "\t\t\tpass\n",
    "\t\t\t# print(\"Failed to parse question:\", question_json_str)\n",
    "\t\texcept pydantic.ValidationError as e:\n",
    "\t\t\tpass\n",
    "\t\n",
    "\treturn questions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = {}\n",
    "fails = {}\n",
    "for raw, file in zip(model_outputs, files):\n",
    "\ttry:\n",
    "\t\tsentences[file] = extract_questions(raw)\n",
    "\texcept:\n",
    "\t\tfails[file] = raw\n",
    "merged_sentences = sum(sentences.values(), start=[])\n",
    "len(merged_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from typing import List\n",
    "\n",
    "\n",
    "# Convert list of dataclass instances to a dataset\n",
    "def convert_to_dataset(questions: List[Question]) -> Dataset:\n",
    "    # Create a dictionary for the dataset\n",
    "    dataset_dict = {\n",
    "        \"question_number\": [question.question_number for question in questions],\n",
    "        \"question_text\": [question.question_text for question in questions],\n",
    "        \"answer_choices\": [convert(question.answer_choices) for question in questions],\n",
    "        \"correct_answers\": [question.correct_answers for question in questions],\n",
    "        \"explanation\": [question.explanation for question in questions]\n",
    "    }\n",
    "\n",
    "    # Create the dataset\n",
    "    dataset = Dataset.from_dict(dataset_dict)\n",
    "    return dataset\n",
    "\n",
    "# Convert the questions list to a Dataset\n",
    "questions_dataset = convert_to_dataset(merged_sentences)\n",
    "\n",
    "# Optionally, print the dataset\n",
    "print(questions_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "correct_answers = pd.Series([j for i in questions_dataset[\"correct_answers\"] for j in i])\n",
    "\n",
    "correct_answers.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questions_dataset.push_to_hub(\"alexneakameni/qa_africa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
